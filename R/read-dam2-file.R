#' @importFrom magrittr "%>%"
#' @importFrom data.table ":="

DAM2_COLS <-  as.list(c("i", "c", "c","i", rep("_",6), rep("i",32)))
names(DAM2_COLS) <- c("idx", "date", "time","status", sprintf("no_data_%02d", 1:6), sprintf("channel_%02d", 1:32))

#' Reads data from a single DAM2 file
#'
#' This function retreives activity data in a DAM2 file.
#' It allows selection of a date range and channels (i.e. regions).
#'
#' @param path location of the file to read (character)
#' @param region_id vector of unique regions to read
#' @param start_datetime,stop_datetime  the start and the end of an the experiment (see details)
#' @param tz the timezone (see [OlsonNames] for a list)
#' @return A [behavr] table.
#' The metadata contains an autogenerated id per animal.
#' The data has the columns:
#' * `id` -- autogenerated unique identifier, one per animal
#' *  `t` -- time
#' * `activity` -- number of beam crosses
#' @details `start_datetime` and `stop_datetime` are formated as "YYYY-MM-DD HH:MM:SS".
#' `start_datetime` is used as the reference time (ZT0).
#' Therefore, if you are interested in circadian analysis and D->L transitions are at 10:00:00,
#' you probably want to set `start_datetime = "YYYY-MM-DD 10:00:00"`.
#' @examples
#' path <- damr_example("M064.txt")
#' dt <- read_dam2_file(path, region_id=c(1:3), start_datetime="2017-06-30 15:00:00")
#' print(dt)
#' @seealso [query_dam2] to load data from many files and biological conditions using a query system
#' @export
read_dam2_file <- function(path,
                            region_id=1:32,
                            start_datetime=-Inf,
                            stop_datetime=+Inf,
                            tz="UTC"){
  # todo check whether region has duplicates/ is in range
  regions <- region_id
  start_datetime <- parse_datetime(start_datetime,tz=tz)
  stop_datetime <- parse_datetime(stop_datetime,tz=tz)

  first_last_lines <- find_dam2_first_last_lines(path,
                                                 start_datetime,
                                                 stop_datetime,
                                                 tz)
  first_line = first_last_lines$id[1]
  last_line = first_last_lines$id[2]
  col_types=do.call(readr::cols_only, DAM2_COLS)
  # todo we do not have to read all regions and hen filter.
  # We can already load only the channels we want here.
  df <-readr::read_tsv(path, col_names = names(DAM2_COLS),
                                 col_types = col_types,
                                 skip = first_line-1,
                                 n_max = last_line-first_line+1,
                                 progress = F)

#  return(start_datetime)
  df <- df %>%
        dplyr::mutate(
          datetime = paste(date,time, sep=" "),
          datetime = as.POSIXct(strptime(datetime,"%d %b %y %H:%M:%S",tz=tz))
        )

   # if start date is not defined, t0 is the first read available, whether or not is is valid!
  if(is.infinite(start_datetime))
    t0 = df$datetime[1]
  else
    t0 = start_datetime
  experiment_id <- paste(format(t0, format = "%F %T"), basename(path),sep="|")
  df <- df %>%
        dplyr::filter(status ==1) %>% # valid reads
        dplyr::distinct(datetime, .keep_all = TRUE) %>% # remove possible duplicates
        dplyr::select(dplyr::matches("(channel)|(datetime)")) %>%
        dplyr::select("0"=dplyr::starts_with("channel_"), dplyr::everything()) %>%
        tidyr::gather(channel,activity,-datetime) %>%
        dplyr::transmute(id= sprintf("%02d|%s",as.integer(channel),experiment_id),
                         region_id = as.integer(channel),
                         t=hms::as.hms(datetime-t0),
                         activity=activity
                         )
  dt <- data.table::data.table(df,key="id")
  # see above todo. we could do the filtering at readtime
  dt <- dt[region_id %in% regions]
  meta <- unique(dt[, c("id","region_id")],by="id")

  meta[,experiment_id := experiment_id]
  meta[,start_datetime:=t0]
  meta[,file:=basename(path)]
  dt[,region_id:=NULL]

  behavr::behavr(dt,meta)
}
